---
layout: post
title: "Docker"
subtitle: "Lecture 3 - Docker Containers (Deadline 2021/09/14 23:55)"
date: 2021-09-12 12:51:32 +0200
categories: jekyll update
background: "/images/image1.jpg"
---

# Introduction

This blog post will be all about working with Docker and containers. We are going to build and run a container based on this repo: [Simple Hello World app](https://github.com/skjohansen/SimpleWebHalloWorld). The second part will be about working with Docker Compose on the same repo (even though it is not really necessary for this particular repository because we are not in any need of multiple containers in this example). But it is a good practice to also work with Docker Compose as it can be needed in the future working with bigger applications because of the need of multiple containers (services). Last step in this blog post will be about building a GitHub pipeline and publish this application to GitHub Registry. When all steps are done, we should be able to pull our created image with `docker pull`.

## Dockerfile

First off, I started with forking the base repository mentioned above. You can find my cloned repository here: [SimpleWebHalloWorld](https://github.com/Orhan92/SimpleWebHalloWorld). So the first step was to make this simple web application to run inside a Docker Container. You can find my Dockerfile here: [Dockerfile](https://github.com/Orhan92/SimpleWebHalloWorld/blob/master/Dockerfile). I will also post a image of the file below.

![Dockerfile](/images/Dokerfile.png){:class="img-fluid"}

It is important to notice that this Dockerfile have been generated by Visual Studio, so I did not have to configure this file myself but I will still go through and explain the various steps of the file. Later on I will also show you my manually configured Dockerfile which can be found here in another branch: [Manually configured Dockerfile](https://github.com/Orhan92/SimpleWebHalloWorld/blob/dockerfile-manual/Dockerfile)

### Explanation of the Dockerfile

As we can see, the first section (row 3-6) will basicallly use aspnet 3.1 as a base image. We are telling our Dockerfile to use `/app` as a working directory and expose the ports, in this case 80. This is to tell our Dockerfile which platform to use as a base. We named this part `AS base`. Next step (row 8-14) inside the Dockerfile, we are also creating the image based on the sdk. We are basically telling our Dockerfile which tools and framework we're using. We will need both the aspnet and SDK to configure our image inside of docker. We have to tell our Dockerfile which platform and framework we're using. Therefore we cannot only tell our Dockerfile to build from aspnet 3.1 solely. We also have to tell our file that we use SDK 3.1 to properly build the image. We name this part of the build `AS build`. This is where the Dockerfile is copying our project inside our repository folder and builds it.
After we have built the application inside our Dockerfile, we are using that build to publish our project and as a last step we are also using our base to build the final step where we are telling our Dockerfile which ENTRYPOINT to use. This is where our file is locating our project and builds the entire image to be able to run it inside a container. This could be simplified by configuring the Dockerfile manually. See the picture below.

![Dockerfile-manual](/images/dockerfile-manual.png){:class="img-fluid"}

I will reference back to the explanation above to explain this image.

### How do we actually run this Docker Image inside of a container?

Well, there are a few steps to be made. But lets assume we have the Dockerfile configured inside of a project. For example, lets take this entire repo: [Simple Hello World](https://github.com/Orhan92/SimpleWebHalloWorld). I will tell you how to run this image step by step down below.

So the first step to do is to direct our console to the working directory (e.g inside the directory where the dockerfile can be found). In my case it would look something like this.

![Working Directory](/images/workdir.png){:class="img-fluid"}

Now that we are inside the working directory, we will have to tell our dockerfile to build the image. This can be done by this command: `docker build . -t simplehelloworld`. Once this command is executed you will see that your dockerfile will start to build based on how you configured it. Notice that `.` will tell our command to build everything and with `-t` we are naming our image. I'll illustrate in the picture below.

![Docker-build](/images/docker-build.png){:class="img-fluid"}

We have now successfully built the image. So the next step would be to run this image / application inside a container. Therefore we need to specify and run the image. You can execute this command: `docker images` to see which images you have built. It should look something like this:

![Docker-image](/images/docker-image.png){:class="img-fluid"}

As you can see our image which we named simplehelloworld will show up together with a image ID. If you want to delete this image you can do so by executing this command: `docker rmi *Image ID*`. Notice that it works perfecty fine if you only give the first 3 letters/digits of the ID. Your image will be removed.

Now that we have our image it is time to run it inside of a container. We can do so by executing this command: `docker run -d -p 8080:80 simplehelloworld`. So this command is running our image inside of a container. The run command makes sure we do that. `-d` tells us to run this container in detached mode and with `-p 8080:80` we are telling our container to run on port 8080 and to listen for port 80 inside of Docker. Now we can actually access our container by opening up our web browser and type: `http://localhost:8080`. Good job, your application is now running inside of a container. I also want to add that `docker ps` command will show you all of your current running containers. If you would like to see a container history you could just execute this command: `docker ps -a`. This way you will see when the container started and when it exited. Lets have a look at the picture below:

![Docker-Container](/images/docker-container.png){:class="img-fluid"}

So as a last step I will show you how to stop your running container and how to delete the container and image. So we basically stop the container by executing: `docker stop 12c`. Now that we have stopped the container, we can now proceeed to delete the container: `docker rm 12c`. The `rm` command will delete containers. After we have deleted the container we can safely delete the image (notice that you can not delete an image while there is a container attached to it. So always make sure you delete the container first). To delete the image we execute this command: `docker rmi 617`. We have now successfully stopped the container, deleted it and also deleted the image. See the picture below for demonstration.

![Docker-remove](/images/docker-remove.png){:class="img-fluid"}

## GitHub Pipeline publishing Docker Image with GitHub Registry

In this step it is time to create a pipeline that builds our dockerfile, and if everything passes we will push it to GitHub registry where we later can pull the image with the `docker pull` command.

Lets have a look at the pipeline. You can find the YAML file here: [Pipeline - YAML File](https://github.com/Orhan92/SimpleWebHalloWorld/blob/master/.github/workflows/pipeline%20build.yml)

Or if you prefer, have a look at the picture below.

![Pipeline](/images/docker-pipeline.png){:class="img-fluid"}

I will not go through details of every step in this pipeline. If you would like to know more about that, have a look at my [Continuous Integration Blog Post](https://orhan92.github.io/jekyll/update/2021/09/08/continuous-integration.html). But I will go through what this Pipeline is doing and how it is built. We are triggering our pipeline on every commit that is made which we can tell on this line of code `on: [push] `. This pipeline will, build the application which we will do in the first step`- uses: actions/checkout@v2`. The `QEMU` action is usefull if we want to build against more platforms and the `Buildx` action will create and boot a builder by using [docker-container builder driver](https://github.com/docker/buildx/blob/master/docs/reference/buildx_create.md#driver). Next step is to login into GitHub Container Registry (ghcr.io) where we explicitly tell our pipeline to use our github username as username and a secret token as password. So what is a secret token and how are we able to set this up? If you would like a more detailed answer to this I recommend that you look through this post: [GitHub Tokens and Secrets](https://itnext.io/build-ship-github-container-registry-kubernetes-aa06029b3f21#0075).

Basically, what I did was to navigate to my GitHub account -> Settings -> Developer Settings -> `Personal Access Tokens`. Once I navigated to `Personal Access Tokens` I generated a new token on the upper right corner. See the link above to configure a token. The next step was to generate a `Secret` inside my repository. This is how to navigate to repository settings:

![Repo settings](/images/repo-settings.png){:class="img-fluid"}

Once we navigated our way to the repository settings, the next step would be to go to `Secrets`. Then we have to create a `New repository secret` in the upper right corner. When we create the secret we have to name it exactly the way we are calling for it inside of our YAML file. In our case we have this line of code: `password: secrets.CR_PAT`. That means that our secret should be named `CR_PAT`. Right after we have named the secret, it is time to paste the `Personal Access Token` into the value field, which we created and received in the first step. Great, we are now set and have a secret which our YAML File can read from. This will also be our credentials when we sign into ghcr.io inside of our pipeline. If every step inside of our `jobs:` succeeds then our pipeline will build and push this image into GitHub Registry.

So, how do we know that our image has been pushed into the registry? Well, we can always check that in our GitHub profile.

![Package](/images/package.png){:class="img-fluid"}

If we click on the package, we can see the README file that is connected to the repository AND how to actually pull this image from GitHub Registry.

![Image pull](/images/img-pull.png){:class="img-fluid"}

As a last step, lets have a look at how it is to pull this image based on the information in the image above. So what we will do is to execute the command (in this case inside of CMD) and see inside Docker Desktop if the image was pulled.

![Image pulled from ghcr](/images/image-pulled.png){:class="img-fluid"}

The image was successfully pulled from GitHub Registry as can be seen on the picture.

### Conclusion

A list of what we've been covering in this particular blog post.

- How to create a Dockerfile
- How to build/create an Image
- How to run a container
- How to build a Pipeline that pushed our Docker Image into GitHub Registry
- How to generate tokens and secrets on a particular repository

#### References

[What is Docker?](https://medium.com/swlh/what-exactly-is-docker-1dd62e1fde38)\
[Dockerfile](https://softchris.github.io/pages/dotnet-dockerize.html#create-a-dockerfile)\
[Docker Containers](https://codemag.com/Article/2103061/Introduction-to-Containerization-Using-Docker)\
[Docker Pipeline](https://github.com/docker/build-push-action)\
[Secrets and Tokens](https://itnext.io/build-ship-github-container-registry-kubernetes-aa06029b3f21#0075)
